{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aSpiM0FNyGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7918dcdf-4068-4961-ccfd-a3725df08da7"
      },
      "source": [
        "%cd drive/My\\ Drive/thesis\n",
        "\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/thesis\n",
            "'Computation and Language'   glove.6B.300d.txt\t Graphics\n",
            " data.csv\t\t     glove.6B.50d.txt\t'Information Theory'\n",
            " data.gsheet\t\t     glove.6B.zip\t logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUtfmaX-NFGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "import os, sys , re , unicodedata\n",
        "import numpy as np\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_OvqDmxNMXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bcd16bd2-2981-4c4e-c8c2-4b132c079a02"
      },
      "source": [
        "data = pd.read_csv(\"data.csv\")\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>summary</th>\n",
              "      <th>keywords_freq</th>\n",
              "      <th>keywords_deg</th>\n",
              "      <th>keywords_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9507013v1</td>\n",
              "      <td>indexed languages are interesting in computati...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>unification grammars,string set,computational ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0801.1415v1</td>\n",
              "      <td>a simple review by a linguist, citing many art...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>simple review,quantitative methods,language ty...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1612.07486v2</td>\n",
              "      <td>most existing models for multilingual natural ...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>make predictions,learned efficiently,improve i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1604.08561v1</td>\n",
              "      <td>we introduce a new measure of distance between...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>word embedding,significant high,result confirm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0201082v1</td>\n",
              "      <td>we show a representation of quantum computers ...</td>\n",
              "      <td>create examples,quantum grammars,examples,alge...</td>\n",
              "      <td>create examples,quantum grammars,algebraic app...</td>\n",
              "      <td>quantum grammars,algebraic approach,create exa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                     keywords_ratio\n",
              "0     9507013v1  ...  unification grammars,string set,computational ...\n",
              "1   0801.1415v1  ...  simple review,quantitative methods,language ty...\n",
              "2  1612.07486v2  ...  make predictions,learned efficiently,improve i...\n",
              "3  1604.08561v1  ...  word embedding,significant high,result confirm...\n",
              "4     0201082v1  ...  quantum grammars,algebraic approach,create exa...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tuvNqNqMP-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['summary'],inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnjVK552MZC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "282486e9-3345-40ed-eb0c-743a93e8c052"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) \n",
        "def unicode_to_ascii(s):\n",
        "  s =  ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "  s = re.sub(r\"[^a-zA-Z?¿<>']+\", \" \", s) # Removing non - alphanumeric words\n",
        "  s = re.sub(r\"'\",'',s)\n",
        "  s = s.lower() #To lowercase\n",
        "  return s\n",
        "\n",
        "def preprocess(w):\n",
        "    w = w.lower()\n",
        "    tokens = [w for w in w.split() if not w in stop_words]\n",
        "    w = \" \".join(tokens)\n",
        "    w = unicode_to_ascii(w) # to remove accents\n",
        "    w = w.strip().rstrip()\n",
        "    w = re.sub(r\"([?.!,])\", r\"\", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    return w"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAF96lTM78H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['processed_text'] = data['summary'].apply(preprocess)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1x63I7KNabu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['class'] = data['keywords_freq'].apply(lambda w : \" \".join(w.split(\",\")))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpm3viqxOVrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "08b2ddd1-a8a7-493d-cf1f-865f1b08fc80"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>summary</th>\n",
              "      <th>keywords_freq</th>\n",
              "      <th>keywords_deg</th>\n",
              "      <th>keywords_ratio</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9507013v1</td>\n",
              "      <td>indexed languages are interesting in computati...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>unification grammars,string set,computational ...</td>\n",
              "      <td>indexed languages interesting computational li...</td>\n",
              "      <td>least class indexed languages exactly describe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0801.1415v1</td>\n",
              "      <td>a simple review by a linguist, citing many art...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>simple review,quantitative methods,language ty...</td>\n",
              "      <td>simple review linguist citing many articles ph...</td>\n",
              "      <td>language typology language dynamics simple rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1612.07486v2</td>\n",
              "      <td>most existing models for multilingual natural ...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>make predictions,learned efficiently,improve i...</td>\n",
              "      <td>existing models multilingual natural language ...</td>\n",
              "      <td>treat language language varieties language als...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1604.08561v1</td>\n",
              "      <td>we introduce a new measure of distance between...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>word embedding,significant high,result confirm...</td>\n",
              "      <td>introduce new measure distance languages based...</td>\n",
              "      <td>natural languages languages classification lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0201082v1</td>\n",
              "      <td>we show a representation of quantum computers ...</td>\n",
              "      <td>create examples,quantum grammars,examples,alge...</td>\n",
              "      <td>create examples,quantum grammars,algebraic app...</td>\n",
              "      <td>quantum grammars,algebraic approach,create exa...</td>\n",
              "      <td>show representation quantum computers defines ...</td>\n",
              "      <td>create examples quantum grammars examples alge...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                              class\n",
              "0     9507013v1  ...  least class indexed languages exactly describe...\n",
              "1   0801.1415v1  ...  language typology language dynamics simple rev...\n",
              "2  1612.07486v2  ...  treat language language varieties language als...\n",
              "3  1604.08561v1  ...  natural languages languages classification lan...\n",
              "4     0201082v1  ...  create examples quantum grammars examples alge...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr76OaSkNiWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['processed_class'] = data['class'].apply(lambda w : '<BOS> '+ w + ' <EOS>')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50F-ukzb59p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "82afee0b-e59f-4dae-d1c4-8b202cd18051"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>summary</th>\n",
              "      <th>keywords_freq</th>\n",
              "      <th>keywords_deg</th>\n",
              "      <th>keywords_ratio</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>class</th>\n",
              "      <th>processed_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9507013v1</td>\n",
              "      <td>indexed languages are interesting in computati...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>least class,indexed languages,exactly describe...</td>\n",
              "      <td>unification grammars,string set,computational ...</td>\n",
              "      <td>indexed languages interesting computational li...</td>\n",
              "      <td>least class indexed languages exactly describe...</td>\n",
              "      <td>&lt;BOS&gt; least class indexed languages exactly de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0801.1415v1</td>\n",
              "      <td>a simple review by a linguist, citing many art...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>language typology,language dynamics,simple rev...</td>\n",
              "      <td>simple review,quantitative methods,language ty...</td>\n",
              "      <td>simple review linguist citing many articles ph...</td>\n",
              "      <td>language typology language dynamics simple rev...</td>\n",
              "      <td>&lt;BOS&gt; language typology language dynamics simp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1612.07486v2</td>\n",
              "      <td>most existing models for multilingual natural ...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>treat language,language varieties,language,als...</td>\n",
              "      <td>make predictions,learned efficiently,improve i...</td>\n",
              "      <td>existing models multilingual natural language ...</td>\n",
              "      <td>treat language language varieties language als...</td>\n",
              "      <td>&lt;BOS&gt; treat language language varieties langua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1604.08561v1</td>\n",
              "      <td>we introduce a new measure of distance between...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>natural languages,languages classification,lan...</td>\n",
              "      <td>word embedding,significant high,result confirm...</td>\n",
              "      <td>introduce new measure distance languages based...</td>\n",
              "      <td>natural languages languages classification lan...</td>\n",
              "      <td>&lt;BOS&gt; natural languages languages classificati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0201082v1</td>\n",
              "      <td>we show a representation of quantum computers ...</td>\n",
              "      <td>create examples,quantum grammars,examples,alge...</td>\n",
              "      <td>create examples,quantum grammars,algebraic app...</td>\n",
              "      <td>quantum grammars,algebraic approach,create exa...</td>\n",
              "      <td>show representation quantum computers defines ...</td>\n",
              "      <td>create examples quantum grammars examples alge...</td>\n",
              "      <td>&lt;BOS&gt; create examples quantum grammars example...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             id  ...                                    processed_class\n",
              "0     9507013v1  ...  <BOS> least class indexed languages exactly de...\n",
              "1   0801.1415v1  ...  <BOS> language typology language dynamics simp...\n",
              "2  1612.07486v2  ...  <BOS> treat language language varieties langua...\n",
              "3  1604.08561v1  ...  <BOS> natural languages languages classificati...\n",
              "4     0201082v1  ...  <BOS> create examples quantum grammars example...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaiJA07HNzET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "10577998-9df4-4a23-98c1-c91db7d867d9"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['processed_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['processed_class']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'class':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEcUdY2ROlh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text= 200 \n",
        "max_len_summary = 6\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train ,X_test, Y_train, Y_test = train_test_split(list(data['processed_text']),list(data['processed_class']),test_size=0.2,random_state=42,shuffle=True) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYh-a56XZ1fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au5FjCCLPCvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "input_tokenizer.fit_on_texts(X_train)\n",
        "X_train_tokens = input_tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "X_test_tokens = input_tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_train_tokens , maxlen= max_len_text , padding='post')\n",
        "X_test_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_test_tokens , maxlen= max_len_text , padding='post')\n",
        "Source_vocabulary = input_tokenizer.word_index\n",
        "\n",
        "X_vocab_size   =  len(input_tokenizer.word_index) +1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXpQkVWXQIce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_tokenizer = Tokenizer()\n",
        "output_tokenizer.fit_on_texts(Y_train)\n",
        "\n",
        "Y_train_tokens    =   output_tokenizer.texts_to_sequences(Y_train) \n",
        "Y_test_tokens   =   output_tokenizer.texts_to_sequences(Y_test) \n",
        "\n",
        "Y_train_tokens    =   tf.keras.preprocessing.sequence.pad_sequences(Y_train_tokens, maxlen=max_len_summary, padding='post')\n",
        "Y_test_tokens   =   tf.keras.preprocessing.sequence.pad_sequences(Y_test_tokens, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "Y_vocab_size  =   len(output_tokenizer.word_index) +1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDVLvI1EQgK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "# From TensorFlow Implementation https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function &\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BahdanauAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(BahdanauAttention, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWhBsUCC4lHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "535057da-8f9e-4a27-c1ac-99e9cb091106"
      },
      "source": [
        "# !wget nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 20:34:54--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-02 20:34:54--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-02 20:34:54--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.05MB/s    in 6m 26s  \n",
            "\n",
            "2020-08-02 20:41:20 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIT7JwWS4sk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dd8ba019-1ae1-448a-adf1-45b515909f47"
      },
      "source": [
        "# !unzip glove.6B.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uk1ShoW4yZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_dict = {}\n",
        "with open(\"glove.6B.300d.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdgVMnzG4zqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Example from keras.io\n",
        "num_words = min(10000, len(Source_vocabulary) + 1)\n",
        "embedding_matrix = np.zeros((num_words, 300))\n",
        "for word, index in Source_vocabulary.items():\n",
        "    embedding_vector = embeddings_dict.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Wq3VZKRTW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(params):\n",
        "    latent_dim = 300 \n",
        "\n",
        "    # Encoder \n",
        "    encoder_inputs = Input(shape=(max_len_text,)) \n",
        "    enc_emb = Embedding(X_vocab_size, latent_dim,trainable=True, weights=[embedding_matrix])(encoder_inputs) \n",
        "\n",
        "    #LSTM 1 \n",
        "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "    #LSTM 2 \n",
        "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "    #LSTM 3 \n",
        "    encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "    # Set up the decoder. \n",
        "    decoder_inputs = Input(shape=(None,)) \n",
        "    dec_emb_layer = Embedding(Y_vocab_size, latent_dim,trainable=True) \n",
        "    dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "    #LSTM using encoder_states as initial state\n",
        "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "    #Attention Layer\n",
        "    attn_layer = BahdanauAttention(name=\"attention\") \n",
        "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "    # Concat attention output and decoder LSTM output \n",
        "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "    #Dense layer\n",
        "    decoder_dense = TimeDistributed(Dense(Y_vocab_size, activation='softmax')) \n",
        "    decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "    rmsprop = tf.keras.optimizers.RMSprop(learning_rate=params[0])\n",
        "    # Define the model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy') \n",
        "    model.summary()\n",
        "\n",
        "    # encoder inference\n",
        "    \n",
        "    encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "    # decoder inference\n",
        "    # Below tensors will hold the states of the previous time step\n",
        "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "    decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "    # Get the embeddings of the decoder sequence\n",
        "    dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "    # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "    decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "    #attention inference\n",
        "    attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "    # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "    decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "    # Final decoder model\n",
        "    decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "    return model , encoder_model , decoder_model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UxRalOVmL1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnOobfyQRuhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "64eff9bb-d6c4-4122-fbaa-c49e25c8836c"
      },
      "source": [
        "params = [\n",
        "    {\n",
        "        'learning_rate': 0.001,\n",
        "        'min': 0.0001,\n",
        "        'max': 0.1,\n",
        "        'low': 0.000001,\n",
        "        'high': 1,\n",
        "        'type': float,\n",
        "    },\n",
        "    {\n",
        "        'input_dim': 30,\n",
        "        'min': 8,\n",
        "        'max': 16,\n",
        "        'low': 4,\n",
        "        'high': 16,\n",
        "        'type': int,\n",
        "        'step' : 1\n",
        "    }\n",
        "]\n",
        "model , encoder_model , decoder_model = get_model([0.0001 , 16])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 200, 300)     2283900     input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(None, 200, 300), ( 721200      embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_13 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  [(None, 200, 300), ( 721200      lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 300)    759000      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_18 (LSTM)                  [(None, 200, 300), ( 721200      lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  [(None, None, 300),  721200      embedding_9[0][0]                \n",
            "                                                                 lstm_18[0][1]                    \n",
            "                                                                 lstm_18[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_18[0][0]                    \n",
            "                                                                 lstm_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_19[0][0]                    \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asQbPzBZSVom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "90ddbf76-8503-4570-8885-64fd5ad4a47e"
      },
      "source": [
        "history= model.fit([X_train_tokens,Y_train_tokens[:,:-1]], Y_train_tokens.reshape(Y_train_tokens.shape[0],Y_train_tokens.shape[1], 1)[:,1:] ,epochs=20,batch_size=64, validation_split=0.2)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 6.1549 - val_loss: 6.3485\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.9998 - val_loss: 6.3250\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.8906 - val_loss: 6.3314\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.8102 - val_loss: 6.3585\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 5.7471 - val_loss: 6.3790\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 5.6832 - val_loss: 6.3047\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.6304 - val_loss: 6.3501\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.5913 - val_loss: 6.3731\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 5.5556 - val_loss: 6.3279\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.5371 - val_loss: 6.4574\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.5122 - val_loss: 6.5185\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 1s 132ms/step - loss: 5.4977 - val_loss: 6.5677\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.4794 - val_loss: 6.5574\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.4642 - val_loss: 6.5848\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.4446 - val_loss: 6.5529\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 5.4262 - val_loss: 6.9110\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 5.4051 - val_loss: 6.6458\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 5.4021 - val_loss: 6.7153\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.3583 - val_loss: 7.0289\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 5.3547 - val_loss: 6.8786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjlpl1psSxRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "cd30ae29-3093-4454-cf21-be6bd3edf0be"
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-1e2df9b0b8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5kFXUZMZEHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "reverse_target_word_index = output_tokenizer .index_word \n",
        "reverse_source_word_index = input_tokenizer .index_word \n",
        "target_word_index = output_tokenizer.word_index"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv9fX10LXy_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "619ce91d-ceee-4a72-9498-aa3da07d163a"
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ed75e6c7be0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# decoder inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Below tensors will hold the states of the previous time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdecoder_state_input_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdecoder_state_input_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdecoder_hidden_state_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'latent_dim' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcXpwhL1Yf3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    # print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['bos']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        # print(\"sampled_token:\",sampled_token)\n",
        "        if(sampled_token!='eos'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eos' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # stop_condition = True\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5CCbduOYisu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['bos']) and i!=target_word_index['eos']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTM3ue-1bFmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reverse_source_word_index = {y:x for x,y in reverse_source_word_index.items()}\n",
        "def eval_summarizer(X):\n",
        "    resp = list()\n",
        "    for x in X:\n",
        "        resp.append(decode_sequence(x.reshape(1,max_len_text) ))\n",
        "    return resp"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J228faylYlbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "64a6da77-41e8-4149-b3a4-43b9219c6c34"
      },
      "source": [
        "for i in range(5):\n",
        "  print(\"Review:\",seq2text(X_test_tokens[i]))\n",
        "  print(\"Original summary:\",seq2summary(Y_test_tokens[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(X_test_tokens[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: graphical modelling long history statistics tool analysis multivariate data starting path analysis gibbs applications statistical physics beginning last century modern form lauritzen pearl s since found applications fields diverse bioinformatics satisfaction surveys weather genetics systems biology unique among fields dimension data sets study often contain several hundreds variables tens hundreds observations raises problems computational complexity statistical significance resulting networks known dimensionality furthermore data difficult model correctly due limited understanding underlying mechanisms following illustrate challenges affect practical graphical modelling possible solutions \n",
            "Original summary: sets statistical statistical physics analysis \n",
            "Predicted summary:  graphical graphical graphical\n",
            "\n",
            "\n",
            "Review: using functional derivatives respect free correlation function derive closed set equations phi theory conversion graphical recursion relations allows us systematically generate connected one particle irreducible feynman diagrams two four point function together weights \n",
            "Original summary: equations closed set weights two \n",
            "Predicted summary:  graphical graphical graphical\n",
            "\n",
            "\n",
            "Review: s b rao conjectured graphic degree sequences well quasi ordered relation defined terms induced subgraph relation m p proved long standing conjecture giving structure theorems graphic degree sequences paper prove use variant commutative theory give short proof bounded degree case conjecture independent structure theory fact answer two questions n robertson first implies bounded degree case conjecture \n",
            "Original summary: short proof relation defined \n",
            "Predicted summary:  graphical graphical graphical model\n",
            "\n",
            "\n",
            "Review: paper show finite two graphics i i triple point type inside quadratic vector fields results contribute program launched program show existence uniform upper bound number limit cycles planar quadratic vector fields \n",
            "Original summary: program program results limit finite \n",
            "Predicted summary:  graphical graphical graphical graphics\n",
            "\n",
            "\n",
            "Review: describe work control graphics rendering limited computational resources taking decision theoretic perspective perceptual costs computational savings approximations work extends earlier work control rendering introducing methods models computing expected cost associated degradations scene components expected cost computed considering perceptual cost degradations probability distribution focus review critical literature describing findings visual search attention discuss implications findings introduce models expected perceptual cost finally discuss harness information expected cost scene components \n",
            "Original summary: cost introduce models expected cost \n",
            "Predicted summary:  graphical graphical graphical\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7vYwjwY0I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGgRQTw6a0uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow import keras\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "\n",
        "\n",
        "class Genetic():\n",
        "    def __init__(self, X_train, Y_train, X_test, Y_test, params, model_fn , eval_fn=None):\n",
        "        self.X_train = X_train\n",
        "        self.Y_train = Y_train\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.hyper_params = params\n",
        "        self.tuneable_params = list()\n",
        "        self.score_fn = None\n",
        "        self.model_fn = model_fn\n",
        "        self.eval_fn = eval_fn\n",
        "\n",
        "    def set_population(self, p):\n",
        "        self.population = p\n",
        "\n",
        "    def init_population(self, parents=8):\n",
        "        for i, e in enumerate(self.hyper_params):\n",
        "            self.tuneable_params.append(\n",
        "                np.empty([parents, 1], dtype=e['type']))\n",
        "            for j in range(parents):\n",
        "                if 'step' in e:\n",
        "                    self.tuneable_params[i][j] = random.randrange(\n",
        "                        e['min'], e['max'], step=e['step'])\n",
        "                else:\n",
        "                    self.tuneable_params[i][j] = random.uniform(\n",
        "                        e['min'], e['max'])\n",
        "        self.population = np.asarray(self.tuneable_params)\n",
        "        self.population = np.concatenate(self.population, axis=1)\n",
        "        return self.population\n",
        "\n",
        "    def set_score_fn(self, score_fn):\n",
        "        self.score_fn = score_fn\n",
        "\n",
        "    def score(self, y_pred):\n",
        "        if self.score_fn is None:\n",
        "            self.score_fn = f1_score\n",
        "        return self.score_fn(y_pred, self.Y_test)\n",
        "\n",
        "    # train the data annd find fitness score\n",
        "\n",
        "    \n",
        "    def train__population(self):\n",
        "        fScore = []\n",
        "        for i in range(self.population.shape[0]):\n",
        "            print('param', self.population[i][0])\n",
        "            model , _ ,_ = self.model_fn(self.population[i])\n",
        "            \n",
        "            # model.fit([X_train_tokens,Y_train_tokens[:,:-1]], Y_train_tokens.reshape(Y_train_tokens.shape[0],Y_train_tokens.shape[1], 1)[:,1:] ,epochs=200,batch_size=64, validation_split=0.2)\n",
        "            model.fit([self.X_train,self.Y_train[:,:-1]], \\\n",
        "                            self.Y_train.reshape(self.Y_train.shape[0],self.Y_train.shape[1], 1)[:,1:] , \n",
        "                            epochs=5,batch_size=64, validation_split=0.2)\n",
        "            if not self.eval_fn:\n",
        "                preds = model.predict(self.X_test)\n",
        "                preds = preds > 0.5\n",
        "            else:\n",
        "                preds = self.eval_fn(self.X_test)\n",
        "            fScore.append(self.score(preds))\n",
        "\n",
        "        self.curr_score = np.asarray(fScore)\n",
        "        return fScore\n",
        "\n",
        "    # Survial of fittest\n",
        "\n",
        "    def form_parents(self, population, fitness_scores, n_parents):\n",
        "        selectedParents = np.empty((n_parents, population.shape[1]))\n",
        "\n",
        "        for i in range(n_parents):\n",
        "            max_score = np.where(fitness_scores == np.max(fitness_scores))\n",
        "            max_score = max_score[0][0]\n",
        "            selectedParents[i, :] = population[max_score, :]\n",
        "            fitness_scores[max_score] = -1\n",
        "        return selectedParents\n",
        "\n",
        "\n",
        "    \n",
        "    def crossover_uniform(self, parents, childrenSize):\n",
        "\n",
        "        crossoverPointIndex = np.arange(0, np.uint8(\n",
        "            childrenSize[1]), 1, dtype=np.uint8)  # get all the index\n",
        "        crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(\n",
        "            childrenSize[1]/2))  # select half  of the indexes randomly\n",
        "        crossoverPointIndex2 = np.array(list(\n",
        "            set(crossoverPointIndex) - set(crossoverPointIndex1)))  # select leftover indexes\n",
        "\n",
        "        children = np.empty(childrenSize)\n",
        "\n",
        "        for i in range(childrenSize[0]):\n",
        "\n",
        "            # find parent 1 index\n",
        "            parent1_index = i % parents.shape[0]\n",
        "            # find parent 2 index\n",
        "            parent2_index = (i+1) % parents.shape[0]\n",
        "            # insert parameters based on random selected indexes in parent 1\n",
        "            children[i, crossoverPointIndex1] = parents[parent1_index,\n",
        "                                                        crossoverPointIndex1]\n",
        "            # insert parameters based on random selected indexes in parent 1\n",
        "            children[i, crossoverPointIndex2] = parents[parent2_index,\n",
        "                                                        crossoverPointIndex2]\n",
        "        return children\n",
        "\n",
        "    def mutation(self, crossover, n_params):\n",
        "        # Define minimum and maximum values allowed for each parameter\n",
        "\n",
        "        m_value = np.zeros((n_params, 2))\n",
        "        for i, e in enumerate(self.hyper_params):\n",
        "            m_value[i, :] = [e['min'], e['max']]\n",
        "\n",
        "        mutationValue = 0\n",
        "        rand_mutate = np.random.randint(0, len(self.hyper_params), 1)[0]\n",
        "        mutationValue = round(np.random.uniform(\n",
        "            self.hyper_params[rand_mutate]['low'], self.hyper_params[rand_mutate]['high']), 2)\n",
        "\n",
        "        for i in range(crossover.shape[0]):\n",
        "            crossover[i, rand_mutate] = crossover[i,\n",
        "                                                  rand_mutate] + mutationValue\n",
        "            if(crossover[i, rand_mutate] > m_value[rand_mutate, 1]):\n",
        "                crossover[i, rand_mutate] = m_value[rand_mutate, 1]\n",
        "            if(crossover[i, rand_mutate] < m_value[rand_mutate, 0]):\n",
        "                crossover[i, rand_mutate] = m_value[rand_mutate, 0]\n",
        "        return crossover\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    def train(self, n_parents=3, min_parent_mating=2, n_generation=1):\n",
        "        assert min_parent_mating >= 2\n",
        "        assert n_generation > 0\n",
        "        assert n_parents >= 3\n",
        "        n_params = len(self.hyper_params)\n",
        "        population_size = (n_parents, n_params)\n",
        "\n",
        "        population = self.init_population(n_parents)\n",
        "\n",
        "        # define an array to store the fitness  hitory\n",
        "        fitnessHistory = np.empty([n_generation + 1, n_parents])\n",
        "\n",
        "        populationHistory = np.empty(\n",
        "            [(n_generation+1)*n_parents, n_params])\n",
        "\n",
        "        populationHistory[0:n_parents, :] = population\n",
        "\n",
        "        for generation in range(n_generation):\n",
        "            self.curr_gen = generation\n",
        "            print(\"This is number %s generation\" % (generation))\n",
        "\n",
        "            # train the dataset and obtain fitness\n",
        "            fitnessValue = self.train__population()\n",
        "            fitnessHistory[generation, :] = fitnessValue\n",
        "\n",
        "            # best score in the current iteration\n",
        "            print('Best max in the this iteration = {}'.format(\n",
        "                np.max(fitnessHistory[generation, :])))\n",
        "            \n",
        "            with writer.as_default():\n",
        "                tf.summary.scalar(\"generation {0}\".format(generation), self.curr_score.mean(), step=generation)\n",
        "\n",
        "            # survival of the fittest - take the top parents, based on the fitness value and number of parents needed to be selected\n",
        "            parents = self.form_parents(\n",
        "                population=population, fitness_scores=fitnessValue, n_parents=min_parent_mating)\n",
        "\n",
        "            # mate these parents to create children having parameters from these parents (we are using uniform crossover)\n",
        "            children = self.crossover_uniform(parents=parents, childrenSize=(\n",
        "                population_size[0] - parents.shape[0], n_params))\n",
        "\n",
        "            children_mutated = self.mutation(children, n_params)\n",
        "\n",
        "            population[0:parents.shape[0], :] = parents  # fittest parents\n",
        "            population[parents.shape[0]:, :] = children_mutated  # children\n",
        "\n",
        "            populationHistory[(generation+1)*n_parents: (generation+1)*n_parents + n_parents, :] = population\n",
        "            tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "        self.set_population(population)\n",
        "        fitness = self.train__population()\n",
        "        fitnessHistory[generation+1, :] = fitness\n",
        "\n",
        "        # index of the best solution\n",
        "        best = np.where(fitness == np.max(fitness))[0][0]\n",
        "\n",
        "        # Best fitness\n",
        "        print(\"Best fitness is =\", population[best])\n",
        "        # self.plot_parameters(n_generation, n_parents, fitnessHistory, \"fitness (F1-score)\")\n",
        "        return population[best]\n",
        "\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMvLQEcDWxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def score(A, B):\n",
        "    _score = list()\n",
        "    for i, a in enumerate(A):\n",
        "        _score.append(SequenceMatcher(None, a, B[i]).ratio())\n",
        "    return  np.asarray(_score).mean()\n",
        "\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojo2MAjMoXTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "69d5cbbe-b59b-425a-fe4e-87af279304fa"
      },
      "source": [
        "print(score([[\"a\"]] , [[\"a\"]]))\n",
        "f1_score([[\"a\"]], [[\"a\"]])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1305: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if pos_label not in present_labels:\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:565: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask &= (ar1 != a)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7t997SY9FXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = Genetic(X_train_tokens, Y_train_tokens, X_test_tokens, Y_test, params, get_model , eval_summarizer)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn_WGBoo-KXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score_fn = tf.keras.losses.sparse_categorical_crossentropy"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVO1X_n-iK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.set_score_fn(score)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5goa5SK-kVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6908920-67bd-45a8-d022-a01bba38e81a"
      },
      "source": [
        "\n",
        "best = g.train(3,2,1)\n",
        "print(best)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is number 0 generation\n",
            "param 0.06397873716594259\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 200, 300)     2283900     input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  [(None, 200, 300), ( 721200      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  [(None, 200, 300), ( 721200      lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, None, 300)    759000      input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  [(None, 200, 300), ( 721200      lstm_13[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_15 (LSTM)                  [(None, None, 300),  721200      embedding_7[0][0]                \n",
            "                                                                 lstm_14[0][1]                    \n",
            "                                                                 lstm_14[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_14[0][0]                    \n",
            "                                                                 lstm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_15[0][0]                    \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 256ms/step - loss: 12.8593 - val_loss: 12.7589\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 12.8228 - val_loss: 12.7731\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 12.7470 - val_loss: 12.7731\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 12.7430 - val_loss: 12.7731\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 12.7559 - val_loss: 12.7731\n",
            "param 0.002598574446744427\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 200, 300)     2283900     input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(None, 200, 300), ( 721200      embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  [(None, 200, 300), ( 721200      lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 300)    759000      input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_18 (LSTM)                  [(None, 200, 300), ( 721200      lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  [(None, None, 300),  721200      embedding_9[0][0]                \n",
            "                                                                 lstm_18[0][1]                    \n",
            "                                                                 lstm_18[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_18[0][0]                    \n",
            "                                                                 lstm_19[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_19[0][0]                    \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 254ms/step - loss: 7.0488 - val_loss: 6.2758\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 6.0539 - val_loss: 6.5672\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 133ms/step - loss: 5.7654 - val_loss: 6.5197\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 5.5953 - val_loss: 6.6145\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 5.3990 - val_loss: 6.6013\n",
            "param 0.027575428905075014\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_26 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 200, 300)     2283900     input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, 200, 300), ( 721200      embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_27 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  [(None, 200, 300), ( 721200      lstm_20[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, None, 300)    759000      input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_22 (LSTM)                  [(None, 200, 300), ( 721200      lstm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_23 (LSTM)                  [(None, None, 300),  721200      embedding_11[0][0]               \n",
            "                                                                 lstm_22[0][1]                    \n",
            "                                                                 lstm_22[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_22[0][0]                    \n",
            "                                                                 lstm_23[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_23[0][0]                    \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 333ms/step - loss: 14.3017 - val_loss: 15.7525\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 14.8327 - val_loss: 12.2920\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 133ms/step - loss: 12.7570 - val_loss: 8.1542\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 133ms/step - loss: 7.4011 - val_loss: 6.9311\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 135ms/step - loss: 5.2312 - val_loss: 6.9965\n",
            "Best max in the this iteration = 0.2288271583737849\n",
            "param 0.06397873716594259\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 200, 300)     2283900     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 200, 300), ( 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 200, 300), ( 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    759000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200, 300), ( 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 260ms/step - loss: 14.7565 - val_loss: 16.0372\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 16.0322 - val_loss: 16.0372\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 16.0322 - val_loss: 16.0372\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 16.0322 - val_loss: 16.0372\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 16.0322 - val_loss: 16.0372\n",
            "param 0.002598574446744427\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 200, 300)     2283900     input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 200, 300), ( 721200      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 200, 300), ( 721200      lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 300)    759000      input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, 200, 300), ( 721200      lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, None, 300),  721200      embedding_3[0][0]                \n",
            "                                                                 lstm_6[0][1]                     \n",
            "                                                                 lstm_6[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_6[0][0]                     \n",
            "                                                                 lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_7[0][0]                     \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 3s 253ms/step - loss: 7.0866 - val_loss: 6.4884\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 6.0016 - val_loss: 6.4757\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 136ms/step - loss: 5.7693 - val_loss: 6.5650\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 135ms/step - loss: 5.5478 - val_loss: 6.5108\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 5.4336 - val_loss: 6.6590\n",
            "param 0.06397873716594259\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 200, 300)     2283900     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 200, 300), ( 721200      embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 200, 300), ( 721200      lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 300)    759000      input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  [(None, 200, 300), ( 721200      lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  [(None, None, 300),  721200      embedding_5[0][0]                \n",
            "                                                                 lstm_10[0][1]                    \n",
            "                                                                 lstm_10[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention (BahdanauAttention)   ((None, None, 300),  180300      lstm_10[0][0]                    \n",
            "                                                                 lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_11[0][0]                    \n",
            "                                                                 attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, None, 2530)   1520530     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 7,628,530\n",
            "Trainable params: 7,628,530\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 2s 247ms/step - loss: 14.6946 - val_loss: 16.0372\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 16.0575 - val_loss: 16.0372\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 16.0575 - val_loss: 16.0372\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 16.0575 - val_loss: 16.0372\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 16.0575 - val_loss: 16.0372\n",
            "Best fitness is = [ 0.06397874 11.        ]\n",
            "[ 0.06397874 11.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-bmKMPb-nea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}